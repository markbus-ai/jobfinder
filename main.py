import asyncio
import json
import logging
import os
from datetime import datetime

from telegram import Bot
from telegram.constants import ParseMode
from sqlmodel import Session, select

from core.config import settings
from database import engine, create_db_and_tables
from models.JobModels import Job
from services.JobServices import JobService
from services.GroqService import ai_service
from services.RedisServices import MemoryQueue

# Configuraci√≥n de Logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# Cargar datos del CV
try:
    with open("cv.json", "r") as f:
        CV_DATA = json.load(f)
except FileNotFoundError:
    logger.error("cv.json no encontrado. Usando diccionario vac√≠o.")
    CV_DATA = {}

def process_jobs_sync():
    """
    Funci√≥n s√≠ncrona que:
    1. Scrapea ofertas (bloqueante)
    2. Verifica duplicados en DB
    3. Analiza con IA (bloqueante)
    4. Guarda resultados
    5. Retorna lista de notificaciones
    """
    job_service = JobService()
    logger.info("üîé Iniciando scraping de ofertas...")
    
    # B√∫squeda en todos los pa√≠ses de habla hispana
    search_locations = [
        {"loc": "Argentina", "country": "argentina"},
        {"loc": "Spain", "country": "spain"},
        {"loc": "Mexico", "country": "mexico"},
        {"loc": "Colombia", "country": "colombia"},
        {"loc": "Chile", "country": "chile"},
        {"loc": "Peru", "country": "peru"},
        {"loc": "Ecuador", "country": "ecuador"},
        {"loc": "Venezuela", "country": "venezuela"},
        {"loc": "Guatemala", "country": "guatemala"},
        {"loc": "Cuba", "country": "cuba"},
        {"loc": "Bolivia", "country": "bolivia"},
        {"loc": "Dominican Republic", "country": "dominican republic"},
        {"loc": "Honduras", "country": "honduras"},
        {"loc": "Paraguay", "country": "paraguay"},
        {"loc": "El Salvador", "country": "el salvador"},
        {"loc": "Nicaragua", "country": "nicaragua"},
        {"loc": "Costa Rica", "country": "costa rica"},
        {"loc": "Panama", "country": "panama"},
        {"loc": "Uruguay", "country": "uruguay"},
    ]
    
    all_jobs = []
    for target in search_locations:
        try:
            logger.info(f"üîé Buscando 'Python Developer' en {target['loc']}...")
            jobs = job_service.get_latest_jobs(
                term="Python Developer", 
                location=target["loc"], 
                country=target["country"],
                limit=15
            )
            all_jobs.extend(jobs)
        except Exception as e:
            logger.error(f"‚ùå Error buscando en {target['loc']}: {e}")

    # Deduplicar por ID (URL)
    unique_jobs_map = {job.id: job for job in all_jobs}
    scraped_jobs = list(unique_jobs_map.values())
    
    logger.info(f"‚úÖ Se encontraron {len(scraped_jobs)} candidatos √∫nicos totales en todos los pa√≠ses.")
    
    notifications = []
    
    with Session(engine) as session:
        for job in scraped_jobs:
            # Verificar si ya existe por ID (URL)
            existing_job = session.get(Job, job.id)
            if existing_job:
                continue

            logger.info(f"ü§ñ Analizando: {job.title} @ {job.company}")
            
            # An√°lisis de IA
            audit = ai_service.analyze_job(job, CV_DATA)

            # Logging detallado
            logger.info(f"üìä An√°lisis para {job.company} - {job.title}:")
            logger.info(f"   üéØ Score: {audit.match_score}/100 | {'‚úÖ Apto' if audit.is_suitable else '‚ùå No apto'}")
            logger.info(f"   üìù Veredicto: {audit.short_verdict}")
            if audit.missing_skills:
                logger.info(f"   üìâ Faltantes: {', '.join(audit.missing_skills)}")
            if audit.seniority_mismatch:
                logger.info(f"   ‚ö†Ô∏è Alerta: Discrepancia de Seniority")

            # Actualizar campos del modelo con el resultado de la auditor√≠a
            job.ai_match_score = audit.match_score
            job.ai_summary = audit.short_verdict
            # job.is_junior removed as requested
            job.is_suitable = audit.is_suitable
            job.seniority_mismatch = audit.seniority_mismatch
            # Serializamos la lista de skills faltantes a JSON string
            job.missing_skills = json.dumps(audit.missing_skills) if audit.missing_skills else "[]"

            # Guardar en DB
            session.add(job)
            session.commit()
            session.refresh(job)

            # Criterio de Notificaci√≥n: Score >= 70 OR marcado como suitable
            if (job.ai_match_score >= 70 or job.is_suitable) and not job.notified:
                notifications.append({
                    "title": job.title,
                    "company": job.company,
                    "location": job.location,
                    "match_score": job.ai_match_score,
                    "summary": job.ai_summary,
                    "url": job.url,
                    "missing_skills": json.loads(job.missing_skills) if job.missing_skills else [],
                    "seniority_mismatch": job.seniority_mismatch,
                    "is_suitable": job.is_suitable
                })
                
                # Marcar como notificado
                job.notified = True
                session.add(job)
                session.commit()
    
    return notifications

async def scraper_scheduler(queue: MemoryQueue):
    """Loop infinito que ejecuta el scraping cada X tiempo."""
    loop = asyncio.get_running_loop()

    while True:
        try:
            logger.info("‚è≥ Ejecutando ciclo de scraping...")
            
            # Ejecutar la l√≥gica s√≠ncrona en un thread pool para no bloquear el loop async
            jobs_to_notify = await loop.run_in_executor(None, process_jobs_sync)
            
            if jobs_to_notify:
                logger.info(f"üì® Encolando {len(jobs_to_notify)} notificaciones...")
                
                if settings.TELEGRAM_CHAT_ID:
                    for job_data in jobs_to_notify:
                        # Formatear skills faltantes
                        skills_text = ", ".join(job_data['missing_skills']) if job_data['missing_skills'] else "Ninguna detectada"
                        seniority_alert = "\n‚ö†Ô∏è <b>Alerta:</b> Posible discrepancia de seniority" if job_data['seniority_mismatch'] else ""
                        suitability_icon = "‚úÖ" if job_data['is_suitable'] else "‚öñÔ∏è"

                        msg_text = (
                            f"üöÄ <b>{suitability_icon} Oportunidad Encontrada</b>\n\n"
                            f"üè¢ <b>Empresa:</b> {job_data['company']}\n"
                            f"üíº <b>Puesto:</b> {job_data['title']}\n"
                            f"üìç <b>Ubicaci√≥n:</b> {job_data['location']}\n\n"
                            f"üéØ <b>Match:</b> <code>{job_data['match_score']}/100</code>\n"
                            f"üìâ <b>Skills Faltantes:</b> <i>{skills_text}</i>"
                            f"{seniority_alert}\n\n"
                            f"üìù <b>Veredicto IA:</b>\n{job_data['summary']}\n\n"
                            f"<a href='{job_data['url']}'>üîó Ver Vacante en Portal</a>"
                        )
                        await queue.enqueue(settings.TELEGRAM_CHAT_ID, msg_text)
                else:
                    logger.warning("TELEGRAM_CHAT_ID no configurado. No se enviar√°n mensajes.")

            logger.info("üí§ Ciclo finalizado. Durmiendo 5 minutos.")
            
        except Exception as e:
            logger.error(f"‚ùå Error en scraper_scheduler: {e}")
        
        # Esperar 5 minutos (300 segundos)
        await asyncio.sleep(300)

async def telegram_worker(queue: MemoryQueue):
    """Consume mensajes de la cola de memoria y los env√≠a a Telegram."""
    if not settings.TELEGRAM_BOT_TOKEN:
        logger.warning("‚ö†Ô∏è TELEGRAM_BOT_TOKEN no configurado. Worker de Telegram pausado.")
        return

    bot = Bot(token=settings.TELEGRAM_BOT_TOKEN)
    logger.info("üì° Worker de Telegram iniciado (Cola Interna)...")

    while True:
        try:
            msg_data = await queue.dequeue()
            if msg_data:
                chat_id = msg_data.get("chat_id")
                text = msg_data.get("text")
                if chat_id and text:
                    await bot.send_message(
                        chat_id=chat_id, text=text, parse_mode=ParseMode.HTML
                    )
                    logger.info(f"‚úÖ Mensaje enviado a {chat_id}")
        except Exception as e:
            logger.error(f"‚ùå Error en telegram_worker: {e}")
            await asyncio.sleep(5)

async def main():
    print(f"üöÄ Iniciando {settings.PROJECT_NAME} Orchestrator (Redis-Free)...")
    
    # 1. Inicializar DB
    create_db_and_tables()
    print("üíæ Base de datos inicializada.")
    
    # 2. Inicializar Cola compartida en memoria
    shared_queue = MemoryQueue()
    
    # 3. Iniciar tareas concurrentes
    await asyncio.gather(
        telegram_worker(shared_queue),
        scraper_scheduler(shared_queue)
    )

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("üõë Apagando orquestador...")
